node('Dev') {

  def STAGING_DATABASE_NAME = 'cit-stg'
  def PRODUCTION_DATABASE_NAME = 'cit-prod'
  def deploymentEnv = "${params.DEPLOYMENT_ENV}"
  
  stage('Keep Backend repository up to date') {
    dir('backend') {
      def repo = 'backend'
      def gitBranch = 'master'
      def gitUrl = 'https://github.com/canitrust/backend.git'
      try {
        deleteDir()
      } catch (err) {
        echo "Caught: ${err}"
      }
      git branch: gitBranch, url: gitUrl
    }
  }

  stage('Extract to json array data') {
    dir('backend/sync') {
      // For each test case in map.json that is set to "isLive": true, the corresponding test case content from testcases.json is synced to the staging database
      // All tags in tags.json are synced to the staging database
      sh returnStdout: true, script: "python scripts/extractDataScript.py"
    }
  }

  withCredentials([
    usernamePassword(credentialsId: 'mongo-sync-staging', usernameVariable: 'MONGO_STAGING_USER', passwordVariable: 'MONGO_STAGING_PASS'),
    usernamePassword(credentialsId: 'mongo-sync-prod', usernameVariable: 'MONGO_PRODUCTION_USER', passwordVariable: 'MONGO_PRODUCTION_PASS'),
    string(credentialsId: 'devMongoUrl', variable: 'MONGO_URL')
  ]) {
    def MONGO_STAGING_URI = "mongodb+srv://${MONGO_STAGING_USER}:${MONGO_STAGING_PASS}@${env.MONGO_STAGING_HOST}/${STAGING_DATABASE_NAME}"
    def MONGO_PRODUCTION_URI = "mongodb+srv://${MONGO_PRODUCTION_USER}:${MONGO_PRODUCTION_PASS}@${env.MONGO_PRODUCTION_HOST}/${PRODUCTION_DATABASE_NAME}"
    def lastUpdate = ''
    def dateQuery = ''
    def MONGO_BACKEND_URI = "${MONGO_URL}/Backend"

    stage('Extract latest test results from Backend') {
      dir('backend/sync') {
        echo "Connect to Staging DB and get latest update timestamp"
        sh returnStdout: true, script: "mongoexport --uri ${MONGO_STAGING_URI} --collection testresults --sort '{date_lasttest:-1}' --fields date_lasttest --limit 1 --out ./latest_testresult.json"
        
        try {
          sh returnStdout: true, script: "cat ./latest_testresult.json | grep -E '[0-9T:.-]+Z' -o > ./latest_update_timestamp.txt"
        } catch(err) {
          echo "Caught: ${err}"
        }

        script {
          echo "Try to read latest update timestamp"
          lastUpdate = readFile('./latest_update_timestamp.txt')
          if (lastUpdate) {
            echo "Latest update timestamp: ${lastUpdate}"
            lastUpdate = lastUpdate.trim()
            dateQuery = "--query '{date: {\$gt: new Date(\"${lastUpdate}\")}, deprecated: false}'"
          } else {
            dateQuery = "--query '{deprecated: false}'"
            echo "Staging DB does not have any testresult"
          }
        }
        echo "Find all entries since latest timestamp"
        sh returnStdout: true, script: "mongoexport --uri ${MONGO_BACKEND_URI} --collection test_Lab ${dateQuery} --sort '{testCaseNum: 1,  browser: 1, version: 1, variationId: 1, date: -1}' --out ./dataLine.json"
      }
    }

    // If dataLine.json has no data then terminate the pipeline job
    def dataLine = readFile(file: 'backend/sync/dataLine.json')
    if( dataLine.size() == 0 ) {
      echo "No new test results from Backend";
      currentBuild.result = 'SUCCESS'
      return
    }

    stage('Convert entries to Frontend DB format') {
      dir('backend/sync') {
        sh "python3 scripts/translate.py dataLine.json"
      }
    }

    stage('Test: Basic data completeness') {
      dir('backend/test') {
        echo "Running basic completeness tests for new test results"
        sh returnStdout: true, script: "python3 testresult_data_match_test.py"

        echo "Running data completeness tests"
        sh returnStdout: true, script: "python3 data_completeness_test.py"
      }
    }

    stage('Update staging DB with new data') {
      dir('backend/sync') {
        sh returnStdout: true, script: "mongoimport --uri ${MONGO_STAGING_URI} --ssl --collection testcases --drop --jsonArray testcases.db.json"
        sh returnStdout: true, script: "mongoimport --uri ${MONGO_STAGING_URI} --ssl --collection tags --drop --jsonArray tags.db.json"

        echo "Create text indexes for fields title and description"
        sh returnStdout: true, script: "mongo ${MONGO_STAGING_URI} --ssl --eval 'db.testcases.createIndex( { title: \"text\", description: \"text\" } )'"

        if (fileExists('./translated.json')) {
          sh returnStdout: true, script: "mongoimport --uri ${MONGO_STAGING_URI} --ssl --collection testresults --file ./translated.json --jsonArray --mode 'upsert' --upsertFields 'testNumber','browser','browserVer','variationId'"
        }
      }
    }

    stage('Test: Data completeness on Staging') {
      dir('backend/test') {
        echo "Running data completeness tests for test results on staging DB"
        sh returnStdout: true, script: "python3 data_stg_completeness_test.py ${MONGO_STAGING_URI} ${STAGING_DATABASE_NAME}"
      }
    }

    stage('Test: UI tests on Staging') {
      dir('backend/test') {
        echo "Running UI tests on staging"
        def ui_test_job = build job: 'staging-ui-test'
      }
    }

    if (deploymentEnv == "production") {
      stage('Sync to Prod') {
        dir('backend/sync') {
          echo "Syncing all data to production"
          echo "Dump the staging DB"
          sh returnStdout: true, script: "mongodump --uri ${MONGO_STAGING_URI} --ssl -o ."
          echo "Imports data to the production DB"
          sh returnStdout: true, script: "mongorestore --uri ${MONGO_PRODUCTION_URI} --db ${PRODUCTION_DATABASE_NAME} --ssl --drop --dir ${STAGING_DATABASE_NAME}"
        }
      }
    }
  }

  try {
    cleanWs()
  } catch (err) {
    echo "Caught: ${err}"
  }
}